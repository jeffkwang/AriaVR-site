---
title: "It's Been A Week Since the Quest 3 Has Been Released. Here's What I Think."
date: 2023-10-17T06:00:03.527233
authors: ["Jeff Wang"]
tags: ["Commentary"]
categories: ["MetaQuest", "Review", "New"]
description: "Read about my thoughts on the Quest 3 and its implications for future developments."
thumbnail: "/images/gen/blog/content3-0.webp"
alt: "Thumbnail displaying the Quest 3."
image: ""
---

# Key Points
---

* The Quest 3 does all the right things to move towards better horizons with mixed reality.
* What we’re currently seeing is dummy interactions between virtual objects and physical space.
* What spatially aware mixed reality could be.

---

# Quest 3 : Meta’s Debut Into Mixed Reality

|![The Quest 3](/images/gen/blog/content3-1.webp)
|:--:|
| *The Quest 3* |
<br />

The Quest 3 was released last week on October 10 amidst noticeable fanfare. From a first-hand glance, the consensus seems largely positive, noting the improvement of the Quest 3 over the Quest 2. Although regarded as the successor to the Quest 2, the device is actually a first for Meta. While the Quest 2 and, for the most part, Quest Pro are virtual reality headsets, the Quest 3 is a mixed reality headset. Here is a quick comparison of their specs:

## Spec Comparison

|  | Quest 2 | Quest Pro | Quest 3 |
| --- | --- | --- | --- |
| Price | $309.99 | $1049.99 | $529.99 |
| Chip | Snapdragon XR2 Gen 1 | Snapdragon XR2+ Gen 1 | Snapdragon XR2 Gen 2 |
| Ergonomics | Soft strap | Counter-balanced ergonomic design | Soft strap |
| Display Resolution | 1832 x 1920 | 1800 x 1920 | 2064 x 2208 |
| Optics | Fresnel lens, 3 position IAD adjust | Pancake lens, continuous IAD with slider | Pancake lens, continuous IAD |
| Face/Eye Tracking | No | Yes | No |
| Controller Tracking | IR based, tracked by headset | Hybrid (IR/Self-tracking) based | Self-tracked with 3 camera sensors |
| Passthrough Fidelity | Greyscale | Color (8 PPD) | Color (18 PPD) |
| Battery | 3640 mAh | 5348 mAh | 5060 mAh |
| Battery Life | 2 hours | 2.5 hours | 2.2 hours |

## Terminology

- **Price:** As specified
- **Chip:** As the stand-in for System on a Chip (SoC), the microchip integrates communication between the GPU, memory, USB controller, power management circuits, and wireless radios.
- **Ergonomics:** Refers to the headset strap build, aimed to eliminate discomfort in use
- **Display Resolution:** How many pixels are present in a display or entire screen; the higher the better
- **Optics:** Refers to lens construction. Pancake lens are a bit thicker and more expensive than Fresnel lens, but they can be much closer to the image and still produce a clear image.
- **Face/Eye Tracking:** Ability of headset to measure and analyze the movements of a person’s eyes to determine where they are looking.
- ************Controller Tracking:************ Mechanism of headset to locate controllers in space.
- **Passthrough Fidelity:** Color and pixels per degree of viewing area in passthrough mode.
- **Battery:** As specified
- **Battery Life:** As specified

The key categories to focus on are passthrough fidelity, display resolution, optics, and the chipset. Currently, Meta's aim with mixed reality is to merge the digital and real. To do this, the headset creates a rendition of reality and, then, overlays it with digital objects. It must act as the bridge between the virtual and real worlds. Therefore, advancements in areas like color, display, optics, and graphics processing are essential.

The Quest 3's introduction of color is a significant step towards an accurate depiction of reality. The improved display resolution means more pixels are included in the display, leading to a clearer visual experience. Enhanced graphics processing minimizes lag and boosts the quality of the displayed content. Additionally, the pancake lens, compared to the Fresnel lens, sits closer to the image, resulting in a more compact and efficient design. 

The Quest 3 is only available in the US, and I am currently writing this from Taiwan. However, my impression of the reviews is largely positive. Coming from the Quest 2 and the Quest Pro, I am excited to see this trend of mixed reality and even more excited to try the Quest 3 when I come back.  

| ![Pancake (left) and Fresnel (right) lens.](/images/gen/blog/content3-2.webp)
|:--:|
| *Pancake (left) and Fresnel (right) lens.* |
<br />

# Spatial Data

Spatial data offers a digital blueprint of our physical surroundings, detailing the size, shape, and location of objects and structures in a room. Meta Quest's utilization of this data allows virtual and real worlds to merge seamlessly. It recognizes and labels items, from furniture to windows, and measures their size, shape, and distance from each other and the headset. Three crucial types of spatial data underpin these interactions:

![Scene data shown as simple shapes. Source: Meta](/images/gen/blog/content3-3.webp)\
*Scene data shown as simple shapes. Source: Meta*

1. **Scene Data**: This provides a simplified model of a space, enabling the VR system to be more aware of the user's environment. Without it, virtual objects can't meaningfully interact with real-world counterparts.

![Mesh data shown as more complex shape forms and textures. Source: Meta](/images/gen/blog/content3-4.webp)\
*Mesh data shown as more complex shape forms and textures. Source: Meta*

2. **Mesh Data**: This is vital for understanding the precise shape and structure of objects in a physical space. In its absence, the interactions between virtual entities and the physical environment lack realism.

![Depth data shown as a heatmap based on proximity. Source: Meta](/images/gen/blog/content3-5.webp)\
*Depth data shown as a heatmap based on proximity. Source: Meta*

3. **Depth Data**: This measures the distance between items in a physical space, ensuring that virtual objects are rendered in a way that feels authentically three-dimensional.

Together, these data types form the foundation for immersive and interactive mixed reality experiences on the Meta Quest 3.

# A Deeper Mixed Reality

Spatial data plays a crucial role in enhancing the mixed reality experience. However, the current availability of spatial data limits the ability of headsets to perceive the surrounding environment. Currently, only visual spatial data is accessible, but there is potential for deeper immersion by incorporating other senses such as motion, heat, pressure, light, and sound.

- Motion sensors track object and human movements, allowing virtual entities to react in real time.
- Pressure sensors measure force, enabling virtual entities to experience push and pull sensations.
- Thermal sensors detect room temperature, allowing virtual reality to adjust accordingly.
- Light sensors assess ambient light conditions, providing realistic shading to virtual objects.
- Sound sensors capture ambient noise, enabling virtual reality to respond accordingly.

These sensors contribute to dynamic interaction, such as the opening and closing of a drawer, where virtual reality can simulate birds flying out. Another example is haptic furniture, where a virtual entity colliding with a table causes vibrations as if it were actually hit.

Improved spatial data can also enhance safety. Proximity sensors in walls or carpets can alert users to potential collisions. Furthermore, the virtual environment can adapt based on proximity data, redirecting users to safer areas.

| ![Ascended Quest Headset](/images/gen/blog/content3-6.webp)
|:--:| 
| *Ascended Quest Headset* |
<br>
# Final Notes

The Quest 3 is finally here, and it is definitely a success by many measures. Moreover, it is a bold move by Meta, very much setting off a technological race. While hardware has not been Meta’s strong suit, they are leveraging what they know best: data. Through spatial data, they know they can create a strong base for a superior device and experience.

Meta may very well be onto something. Spatial data may be the key to better and better mixed reality experiences.